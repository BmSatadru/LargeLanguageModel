{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP4lVkub/VTGDj6+a+bIyrW"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f5a75dcb17ba4c19836e6bcf9b174e01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f7300648467740619406d102cee50b75",
              "IPY_MODEL_017491cbf6864c6b90fc6300868017cf",
              "IPY_MODEL_82e73b0f874a4914b793f381f595805c"
            ],
            "layout": "IPY_MODEL_a0fff3adc65e4c2bbcda3043a9cdac33"
          }
        },
        "f7300648467740619406d102cee50b75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35b5d5cda47b450f923f60c9db4638f5",
            "placeholder": "​",
            "style": "IPY_MODEL_420e5235b90f47669b40fec0883a75d8",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "017491cbf6864c6b90fc6300868017cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a36f66197864c32845c4725a3071eb1",
            "max": 1289,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_131eb4281ec54a1cb38b9650559ac204",
            "value": 1289
          }
        },
        "82e73b0f874a4914b793f381f595805c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e226efba9694b6ea8836ee8a904df37",
            "placeholder": "​",
            "style": "IPY_MODEL_5c0ab60a7be8456385fda09ce0442a56",
            "value": " 1.29k/1.29k [00:00&lt;00:00, 25.8kB/s]"
          }
        },
        "a0fff3adc65e4c2bbcda3043a9cdac33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35b5d5cda47b450f923f60c9db4638f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "420e5235b90f47669b40fec0883a75d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a36f66197864c32845c4725a3071eb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "131eb4281ec54a1cb38b9650559ac204": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e226efba9694b6ea8836ee8a904df37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c0ab60a7be8456385fda09ce0442a56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e4af31a86dc434280c42ceb27361878": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e1dc3401ebd3437180038d865f2b64d8",
              "IPY_MODEL_1e0b0ca94b4040ecbbb206d09ad87d41",
              "IPY_MODEL_f9a809d5d2e34feaa4652d4d2c01b367"
            ],
            "layout": "IPY_MODEL_f0e18efbcfba43998e068f684c36a67c"
          }
        },
        "e1dc3401ebd3437180038d865f2b64d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88987394e64f4ebcac7eae2717973553",
            "placeholder": "​",
            "style": "IPY_MODEL_8c5d598ca5374d588c54198e9352fdeb",
            "value": "tokenizer.model: 100%"
          }
        },
        "1e0b0ca94b4040ecbbb206d09ad87d41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf8738fc2a42417989a9f8d973414576",
            "max": 499723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3c9e3580c3e54937947c9243393c30bd",
            "value": 499723
          }
        },
        "f9a809d5d2e34feaa4652d4d2c01b367": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3f38cc9c1cf4705a7025f5e815977c5",
            "placeholder": "​",
            "style": "IPY_MODEL_f3399e6cfe3f4b418baf004853538fa2",
            "value": " 500k/500k [00:00&lt;00:00, 3.00MB/s]"
          }
        },
        "f0e18efbcfba43998e068f684c36a67c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88987394e64f4ebcac7eae2717973553": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c5d598ca5374d588c54198e9352fdeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf8738fc2a42417989a9f8d973414576": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c9e3580c3e54937947c9243393c30bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e3f38cc9c1cf4705a7025f5e815977c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3399e6cfe3f4b418baf004853538fa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95abe62226e240f799a51161763e8d2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d8fb70c83dd34d16b851689d91b250bf",
              "IPY_MODEL_b5a4c9f1010f48e39c93e1f4db490f11",
              "IPY_MODEL_644af0cc6f7c4de28af92ed5e5e96858"
            ],
            "layout": "IPY_MODEL_b2a92c885dc7409887860063d3304d28"
          }
        },
        "d8fb70c83dd34d16b851689d91b250bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f3c27b235374703920df12d5be6d564",
            "placeholder": "​",
            "style": "IPY_MODEL_3e96696526ce4d7e82fbe8f440a21ec3",
            "value": "tokenizer.json: 100%"
          }
        },
        "b5a4c9f1010f48e39c93e1f4db490f11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5f787a6fac24e73b8a52b7e1931fb69",
            "max": 1842767,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bad6e497475d444c83b7894051d449d9",
            "value": 1842767
          }
        },
        "644af0cc6f7c4de28af92ed5e5e96858": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70ba1593b88041608b36360b56ee2bb4",
            "placeholder": "​",
            "style": "IPY_MODEL_ca0468c5bebc41b1961d76b1107f61ce",
            "value": " 1.84M/1.84M [00:00&lt;00:00, 15.0MB/s]"
          }
        },
        "b2a92c885dc7409887860063d3304d28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f3c27b235374703920df12d5be6d564": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e96696526ce4d7e82fbe8f440a21ec3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5f787a6fac24e73b8a52b7e1931fb69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bad6e497475d444c83b7894051d449d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "70ba1593b88041608b36360b56ee2bb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca0468c5bebc41b1961d76b1107f61ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1757f453c2ec4ba9a7d6ff6b3b47babc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_afcd833f7ac54e46a30f084c43121c2f",
              "IPY_MODEL_5bbd245ff07f441984fc590a2fa1e3b1",
              "IPY_MODEL_8b53f865ea52416ab9fde79899f11297"
            ],
            "layout": "IPY_MODEL_a2b9450ba7f041e5b44d977ae8afe316"
          }
        },
        "afcd833f7ac54e46a30f084c43121c2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13c267e23d3146658d45698af8d6ca0b",
            "placeholder": "​",
            "style": "IPY_MODEL_9611df0421d7405c80ddda96e4714652",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "5bbd245ff07f441984fc590a2fa1e3b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef062827f77e42c2bdb5ac88ad58c003",
            "max": 551,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6dbb8e35bf0b4b3097e0a4d04e9cb36f",
            "value": 551
          }
        },
        "8b53f865ea52416ab9fde79899f11297": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7443f69747bb4584a970acf2fa4e22ec",
            "placeholder": "​",
            "style": "IPY_MODEL_c60bb2fa410b458eab10e44f953e5e9e",
            "value": " 551/551 [00:00&lt;00:00, 5.06kB/s]"
          }
        },
        "a2b9450ba7f041e5b44d977ae8afe316": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13c267e23d3146658d45698af8d6ca0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9611df0421d7405c80ddda96e4714652": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef062827f77e42c2bdb5ac88ad58c003": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6dbb8e35bf0b4b3097e0a4d04e9cb36f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7443f69747bb4584a970acf2fa4e22ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c60bb2fa410b458eab10e44f953e5e9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07d843d7550b4870a7612ff0b42132ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d2c03f569f7f44ef9c56e3cbca7a54e4",
              "IPY_MODEL_a50b34c61bda482890b2e2e342b01341",
              "IPY_MODEL_3acbdb6371bf43cdb5e566bc18de47f0"
            ],
            "layout": "IPY_MODEL_805c20511ef64b01a9d34eaba4c95469"
          }
        },
        "d2c03f569f7f44ef9c56e3cbca7a54e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccbb4f26b7554dfdb584836c936fff63",
            "placeholder": "​",
            "style": "IPY_MODEL_12eab4fc0dff475cbd9fe6e5b169eed7",
            "value": "config.json: 100%"
          }
        },
        "a50b34c61bda482890b2e2e342b01341": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00a81323287c476fafdb93a6241af1ef",
            "max": 608,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bb48198b3a2b41099dcc229306e2999c",
            "value": 608
          }
        },
        "3acbdb6371bf43cdb5e566bc18de47f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e26db57b928a48519d152971242e5b48",
            "placeholder": "​",
            "style": "IPY_MODEL_0bdd90c231ed4d31a7ef0f4e0053c8e9",
            "value": " 608/608 [00:00&lt;00:00, 9.09kB/s]"
          }
        },
        "805c20511ef64b01a9d34eaba4c95469": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccbb4f26b7554dfdb584836c936fff63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12eab4fc0dff475cbd9fe6e5b169eed7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00a81323287c476fafdb93a6241af1ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb48198b3a2b41099dcc229306e2999c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e26db57b928a48519d152971242e5b48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bdd90c231ed4d31a7ef0f4e0053c8e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c2cde46ff014e928bd3ad8f2869de9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_82f14b8277ae4737be50866433d55b09",
              "IPY_MODEL_449b8a24fece4756bf2f4f22c53c023f",
              "IPY_MODEL_fa708e2c36bb4db5acd3a80830d07377"
            ],
            "layout": "IPY_MODEL_66e9c04ba63e4cbe8e03a1c24d86ad2f"
          }
        },
        "82f14b8277ae4737be50866433d55b09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b88a5d7fbaf4388b6ee3703b3360630",
            "placeholder": "​",
            "style": "IPY_MODEL_a23f167a805a42ebbafb0fd5bb63f0d3",
            "value": "model.safetensors: 100%"
          }
        },
        "449b8a24fece4756bf2f4f22c53c023f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f91322dbab4248f5a0ca1c9a53f06dc4",
            "max": 2200119864,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dae75d38a181477984ae7950d6753825",
            "value": 2200119864
          }
        },
        "fa708e2c36bb4db5acd3a80830d07377": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b987917cbcb4dab8e3f12b5ad0aabbb",
            "placeholder": "​",
            "style": "IPY_MODEL_9f20e375d29a4b4b84b3c0b449c3333e",
            "value": " 2.20G/2.20G [00:52&lt;00:00, 42.9MB/s]"
          }
        },
        "66e9c04ba63e4cbe8e03a1c24d86ad2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b88a5d7fbaf4388b6ee3703b3360630": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a23f167a805a42ebbafb0fd5bb63f0d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f91322dbab4248f5a0ca1c9a53f06dc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dae75d38a181477984ae7950d6753825": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3b987917cbcb4dab8e3f12b5ad0aabbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f20e375d29a4b4b84b3c0b449c3333e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e32f908fcbf44ae0936e5567771df9fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5daac3329e14c209ea05c0a17b11617",
              "IPY_MODEL_5522c7b01e0b440a909c47118486fd36",
              "IPY_MODEL_fe6912c5309a4907988b977b3a7f5958"
            ],
            "layout": "IPY_MODEL_112a44e4275f473d884ae1673939d981"
          }
        },
        "d5daac3329e14c209ea05c0a17b11617": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c7f57df231540b8b5bfb7d54bfca694",
            "placeholder": "​",
            "style": "IPY_MODEL_5f8a6d1bd2ba400cb49938d0778626d5",
            "value": "generation_config.json: 100%"
          }
        },
        "5522c7b01e0b440a909c47118486fd36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28cb8d028a95425fa948ac17f8a9c5cd",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9fde0f8eb03c448c854933326480b615",
            "value": 124
          }
        },
        "fe6912c5309a4907988b977b3a7f5958": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3952423416a0454da0e34178600f2008",
            "placeholder": "​",
            "style": "IPY_MODEL_fe1e61e6fb644a0983f9a79a81591015",
            "value": " 124/124 [00:00&lt;00:00, 5.22kB/s]"
          }
        },
        "112a44e4275f473d884ae1673939d981": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c7f57df231540b8b5bfb7d54bfca694": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f8a6d1bd2ba400cb49938d0778626d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28cb8d028a95425fa948ac17f8a9c5cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fde0f8eb03c448c854933326480b615": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3952423416a0454da0e34178600f2008": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe1e61e6fb644a0983f9a79a81591015": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3k1u3t1zJElj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## 1. Overview of Decoder-Only Transformers\n",
        "\n",
        "In a **decoder-only transformer** (like GPT-2 or TinyLlama), the goal is to generate text by predicting the next word based on the previous words in a sequence. Decoder transformers are designed to process language from left to right (or sequentially in the context of generation) using **self-attention** and **feed-forward** layers.\n",
        "\n",
        "### 2. Core Components of the Decoder Block\n",
        "\n",
        "Each **decoder block** has three main components:\n",
        "1. **Masked Self-Attention**: Looks at all previous tokens up to the current one, allowing the model to understand the context without seeing future tokens.\n",
        "2. **Feed-Forward Neural Network**: Processes each token’s self-attention output further, adding complexity to the token’s contextual representation.\n",
        "3. **Layer Normalization** and **Residual Connections**: Help stabilize training and maintain gradients across layers.\n",
        "\n",
        "### Step-by-Step Process: Generating Text with Decoder Transformers\n",
        "\n",
        "Imagine the model is given the sentence: “The cat sat on the …” and needs to predict the next word.\n",
        "\n",
        "#### Step 1: Tokenization\n",
        "\n",
        "The input sentence is split into tokens:\n",
        "> [\"The\", \"cat\", \"sat\", \"on\", \"the\"]\n",
        "\n",
        "Each token is assigned an ID from the model’s vocabulary:\n",
        "> [101, 312, 500, 404, 312]\n",
        "\n",
        "The IDs are then transformed into **embedding vectors** — numerical representations that capture semantic information about each token.\n",
        "\n",
        "#### Step 2: Adding Positional Encodings\n",
        "\n",
        "Since transformers don’t have a built-in understanding of sequence order, **positional encodings** are added to each embedding. This allows the model to understand that \"The\" is the first token, \"cat\" the second, and so on.\n",
        "\n",
        "The result is a **position-encoded input** for each token.\n",
        "\n",
        "#### Step 3: Masked Self-Attention\n",
        "\n",
        "**Masked self-attention** is used to prevent each token from seeing future tokens in the sequence. For example:\n",
        "- When processing \"The,\" the model attends only to \"The.\"\n",
        "- When processing \"cat,\" the model attends to \"The\" and \"cat\" but not to any token after \"cat.\"\n",
        "\n",
        "In mathematical terms:\n",
        "1. **Query (Q), Key (K), and Value (V)** vectors are generated for each token.\n",
        "2. Attention scores are calculated by taking the **dot product** of each token's Query with every other token's Key.\n",
        "3. These scores are scaled and passed through **softmax** to form attention weights.\n",
        "\n",
        "The attention weight of each token is applied to its corresponding Value vector, and these weighted values are summed to form a **self-attention output** for each token. The attention mask ensures future tokens have zero attention.\n",
        "\n",
        "#### Step 4: Feed-Forward Neural Network\n",
        "\n",
        "After self-attention, the output for each token is passed through a **feed-forward layer** (a small neural network) that adds non-linear transformations. This helps capture complex relationships in the data that go beyond linear dependencies.\n",
        "\n",
        "#### Step 5: Stacking Decoder Blocks\n",
        "\n",
        "The model stacks multiple decoder blocks on top of each other. Each block refines the representation of each token, allowing the model to capture intricate dependencies between words.\n",
        "\n",
        "For example:\n",
        "- In early layers, the model might capture simple word associations (like \"sat\" and \"on\").\n",
        "- In deeper layers, the model can capture more abstract relationships (like understanding that \"The cat sat on the mat\" describes an action).\n",
        "\n",
        "#### Step 6: Predicting the Next Token\n",
        "\n",
        "After the last decoder block, the model produces **output embeddings** for each token in the sequence. The final layer is a **softmax layer** that converts these embeddings into probabilities for each token in the vocabulary. The token with the highest probability is chosen as the **next token** in the sequence.\n",
        "\n",
        "#### Example Calculation for Self-Attention\n",
        "\n",
        "Let’s go through a simplified calculation using the word “The” from our example sentence. Assume \"The\" is at position 1.\n",
        "\n",
        "1. **Query, Key, and Value Vectors**: These are generated by multiplying the embedding of \"The\" with weight matrices $W_q$, $ W_k $, and $ W_v $ respectively.\n",
        "2. **Attention Score Calculation**:\n",
        "   $\n",
        "   \\text{Attention Score}_{\\text{The, cat}} = \\frac{Q_{\\text{The}} \\cdot K_{\\text{cat}}^T}{\\sqrt{d}}\n",
        "   $\n",
        "   The scores for \"The\" with itself and other words like \"cat\" are computed.\n",
        "3. **Masking**: If \"The\" is the first word, it won’t attend to future words (like \"sat\" or \"on\").\n",
        "4. **Softmax**: Scores are normalized to probabilities, emphasizing important tokens.\n",
        "5. **Weighted Sum with Values**: The probability weights are applied to Value vectors to get a final representation for \"The.\"\n",
        "\n",
        "### Summary\n",
        "\n",
        "The decoder transformer:\n",
        "1. Takes an input sentence and tokenizes it.\n",
        "2. Adds positional encodings to preserve word order.\n",
        "3. Applies masked self-attention and feed-forward layers, refining each token’s representation while only attending to previous tokens.\n",
        "4. Stacks multiple layers to capture complex relationships.\n",
        "5. Predicts the next word by choosing the token with the highest probability.\n",
        "\n",
        "This approach allows decoder-based transformers to generate coherent, context-aware text by building on previous words, one token at a time, in a left-to-right fashion."
      ],
      "metadata": {
        "id": "9AJmJLGiC5vn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a **decoder-only transformer architecture** (like GPT-2 or TinyLlama), each decoder block is connected in a stacked manner, where the output from one block is fed into the next one, refining the token representation at each step. The core idea is that each block processes the sequence and passes its output to the next block, which helps the model build increasingly sophisticated representations of the input sequence.\n",
        "\n",
        "### How the Decoder Blocks are Connected:\n",
        "\n",
        "#### 1. **Initial Input Embeddings and Positional Encodings**:\n",
        "   - The input tokens (e.g., \"The cat sat on the\") are first converted into embeddings.\n",
        "   - Positional encodings are added to these embeddings to retain the order of the tokens, as transformers process tokens in parallel (not sequentially).\n",
        "\n",
        "#### 2. **First Decoder Block**:\n",
        "   - The **input embeddings** (tokens + positional encodings) are passed into the first decoder block.\n",
        "   - The block performs **masked self-attention** on the input. This means each token only attends to the tokens before it, ensuring that the model doesn’t have access to future tokens.\n",
        "   - After self-attention, the output is passed through a **feed-forward neural network** to add non-linearity and complexity.\n",
        "   - The result is a refined representation of each token, which contains information about both its position and its contextual relationship to the other tokens (before it).\n",
        "\n",
        "#### 3. **Subsequent Decoder Blocks**:\n",
        "   - The output from the first decoder block is passed into the **next decoder block**.\n",
        "   - Each subsequent block has the same structure (masked self-attention + feed-forward), but the input is the output of the previous block.\n",
        "   - Each block builds on the previous block's output, refining and adding more complex relationships to the representations.\n",
        "\n",
        "#### 4. **Residual Connections**:\n",
        "   - To help with training, **residual connections** are used. These connections allow the input of a block to be added directly to its output before it is passed to the next block.\n",
        "   - This helps to prevent issues like vanishing gradients and ensures the model learns efficiently.\n",
        "\n",
        "#### 5. **Final Output**:\n",
        "   - After passing through all the decoder blocks, the final output representation for each token is produced.\n",
        "   - The output is then used to predict the next token in the sequence by applying a **linear transformation** followed by **softmax** to generate probabilities.\n",
        "\n",
        "### Visualization of Decoder Blocks Connection:\n",
        "Consider 3 decoder blocks (Block 1, Block 2, and Block 3):\n",
        "\n",
        "1. **Input Layer** (Token embeddings + Positional Encodings):\n",
        "   - These are passed into **Block 1**.\n",
        "\n",
        "2. **Block 1**:\n",
        "   - Performs masked self-attention and a feed-forward pass.\n",
        "   - Output of **Block 1** is passed to **Block 2**.\n",
        "\n",
        "3. **Block 2**:\n",
        "   - The output of **Block 1** is further refined through masked self-attention and a feed-forward pass.\n",
        "   - Output of **Block 2** is passed to **Block 3**.\n",
        "\n",
        "4. **Block 3**:\n",
        "   - The output of **Block 2** is refined even further.\n",
        "   - Final output is passed to the **prediction layer**.\n",
        "\n",
        "### Mathematical Flow (Simplified):\n",
        "\n",
        "Let’s simplify the mathematical flow for a sentence \"The cat sat on the\":\n",
        "\n",
        "1. **Token Embeddings**:\n",
        "   \n",
        "   $\\text{Embedding}_i = \\text{Embed}(token_i) + \\text{PositionalEncoding}_i$\n",
        "   \n",
        "   for each token $i$ in the sequence.\n",
        "\n",
        "2. **Masked Self-Attention**:\n",
        "   For each token, the attention score is computed with:\n",
        "   \n",
        "   $\\text{Attention Score} = \\frac{Q_i \\cdot K_j^T}{\\sqrt{d}}$\n",
        "   \n",
        "   where $Q_i$ is the query vector for token $i$, and $K_j$ is the key vector for token $j$. The attention mask ensures that token $i$ does not attend to any token $j$ where $j > i$ (future tokens).\n",
        "\n",
        "3. **Feed-Forward Layer**:\n",
        "   After self-attention, a feed-forward network is applied to each token’s representation:\n",
        "   \n",
        "   $\\text{Output}_i = \\text{FeedForward}\\text({Attention Output}_i)$\n",
        "   \n",
        "\n",
        "4. **Stacked Decoder Blocks**:\n",
        "   Each decoder block refines the output from the previous block:\n",
        "   $\n",
        "   \\text{Output of Block 1} \\to \\text{Block 2} \\to \\text{Block 3} \\to \\cdots\n",
        "   $\n",
        "\n",
        "5. **Final Layer**:\n",
        "   After passing through all the decoder blocks, the final output is passed through a softmax layer to predict the next token:\n",
        "   $\n",
        "   \\text{Predicted Next Token} = \\arg\\max(\\text{Softmax}(\\text{Logits}_i))\n",
        "   $\n",
        "\n",
        "### Code Explanation for Decoder Block Connections:\n",
        "\n",
        "In the code, each decoder block is implemented as part of the transformer model. The following code snippet shows how the layers are stacked and processed through a model like GPT-2 or TinyLlama:"
      ],
      "metadata": {
        "id": "NGTj-oI0_Vb6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below code is an example of how a decoder-based transformer predict the `next word` of a given prompt\n",
        "\n",
        "```python\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# Load model and tokenizer\n",
        "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "# Example prompt\n",
        "prompt = \"The cat sat on the\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "# Forward pass through the model (which includes multiple decoder blocks)\n",
        "outputs = model(**inputs)\n",
        "\n",
        "# The logits represent the final output after all decoder blocks\n",
        "next_token_logits = outputs.logits[:, -1, :]  # Logits for the last token\n",
        "\n",
        "# Convert logits to probabilities and pick the highest\n",
        "next_token = torch.argmax(next_token_logits, dim=-1)\n",
        "predicted_word = tokenizer.decode(next_token)\n",
        "\n",
        "print(f\"Predicted next word: {predicted_word}\")\n",
        "```\n",
        "We will discuss the code block by block and will see what is happening in the back-end"
      ],
      "metadata": {
        "id": "aykatZmHIefk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch"
      ],
      "metadata": {
        "id": "8-enIBbUAyH3"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model and tokenizer\n",
        "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "OUxbt0UpA0Op",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241,
          "referenced_widgets": [
            "f5a75dcb17ba4c19836e6bcf9b174e01",
            "f7300648467740619406d102cee50b75",
            "017491cbf6864c6b90fc6300868017cf",
            "82e73b0f874a4914b793f381f595805c",
            "a0fff3adc65e4c2bbcda3043a9cdac33",
            "35b5d5cda47b450f923f60c9db4638f5",
            "420e5235b90f47669b40fec0883a75d8",
            "4a36f66197864c32845c4725a3071eb1",
            "131eb4281ec54a1cb38b9650559ac204",
            "0e226efba9694b6ea8836ee8a904df37",
            "5c0ab60a7be8456385fda09ce0442a56",
            "1e4af31a86dc434280c42ceb27361878",
            "e1dc3401ebd3437180038d865f2b64d8",
            "1e0b0ca94b4040ecbbb206d09ad87d41",
            "f9a809d5d2e34feaa4652d4d2c01b367",
            "f0e18efbcfba43998e068f684c36a67c",
            "88987394e64f4ebcac7eae2717973553",
            "8c5d598ca5374d588c54198e9352fdeb",
            "cf8738fc2a42417989a9f8d973414576",
            "3c9e3580c3e54937947c9243393c30bd",
            "e3f38cc9c1cf4705a7025f5e815977c5",
            "f3399e6cfe3f4b418baf004853538fa2",
            "95abe62226e240f799a51161763e8d2a",
            "d8fb70c83dd34d16b851689d91b250bf",
            "b5a4c9f1010f48e39c93e1f4db490f11",
            "644af0cc6f7c4de28af92ed5e5e96858",
            "b2a92c885dc7409887860063d3304d28",
            "2f3c27b235374703920df12d5be6d564",
            "3e96696526ce4d7e82fbe8f440a21ec3",
            "c5f787a6fac24e73b8a52b7e1931fb69",
            "bad6e497475d444c83b7894051d449d9",
            "70ba1593b88041608b36360b56ee2bb4",
            "ca0468c5bebc41b1961d76b1107f61ce",
            "1757f453c2ec4ba9a7d6ff6b3b47babc",
            "afcd833f7ac54e46a30f084c43121c2f",
            "5bbd245ff07f441984fc590a2fa1e3b1",
            "8b53f865ea52416ab9fde79899f11297",
            "a2b9450ba7f041e5b44d977ae8afe316",
            "13c267e23d3146658d45698af8d6ca0b",
            "9611df0421d7405c80ddda96e4714652",
            "ef062827f77e42c2bdb5ac88ad58c003",
            "6dbb8e35bf0b4b3097e0a4d04e9cb36f",
            "7443f69747bb4584a970acf2fa4e22ec",
            "c60bb2fa410b458eab10e44f953e5e9e",
            "07d843d7550b4870a7612ff0b42132ab",
            "d2c03f569f7f44ef9c56e3cbca7a54e4",
            "a50b34c61bda482890b2e2e342b01341",
            "3acbdb6371bf43cdb5e566bc18de47f0",
            "805c20511ef64b01a9d34eaba4c95469",
            "ccbb4f26b7554dfdb584836c936fff63",
            "12eab4fc0dff475cbd9fe6e5b169eed7",
            "00a81323287c476fafdb93a6241af1ef",
            "bb48198b3a2b41099dcc229306e2999c",
            "e26db57b928a48519d152971242e5b48",
            "0bdd90c231ed4d31a7ef0f4e0053c8e9",
            "2c2cde46ff014e928bd3ad8f2869de9f",
            "82f14b8277ae4737be50866433d55b09",
            "449b8a24fece4756bf2f4f22c53c023f",
            "fa708e2c36bb4db5acd3a80830d07377",
            "66e9c04ba63e4cbe8e03a1c24d86ad2f",
            "9b88a5d7fbaf4388b6ee3703b3360630",
            "a23f167a805a42ebbafb0fd5bb63f0d3",
            "f91322dbab4248f5a0ca1c9a53f06dc4",
            "dae75d38a181477984ae7950d6753825",
            "3b987917cbcb4dab8e3f12b5ad0aabbb",
            "9f20e375d29a4b4b84b3c0b449c3333e",
            "e32f908fcbf44ae0936e5567771df9fd",
            "d5daac3329e14c209ea05c0a17b11617",
            "5522c7b01e0b440a909c47118486fd36",
            "fe6912c5309a4907988b977b3a7f5958",
            "112a44e4275f473d884ae1673939d981",
            "3c7f57df231540b8b5bfb7d54bfca694",
            "5f8a6d1bd2ba400cb49938d0778626d5",
            "28cb8d028a95425fa948ac17f8a9c5cd",
            "9fde0f8eb03c448c854933326480b615",
            "3952423416a0454da0e34178600f2008",
            "fe1e61e6fb644a0983f9a79a81591015"
          ]
        },
        "outputId": "e7acdbd6-ffaf-42e8-b7b1-5264b55ae71e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f5a75dcb17ba4c19836e6bcf9b174e01"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e4af31a86dc434280c42ceb27361878"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "95abe62226e240f799a51161763e8d2a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1757f453c2ec4ba9a7d6ff6b3b47babc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "07d843d7550b4870a7612ff0b42132ab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c2cde46ff014e928bd3ad8f2869de9f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e32f908fcbf44ae0936e5567771df9fd"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQjLjU1LD3Gg",
        "outputId": "46dbc0a0-b484-48f8-c881-6d2de41c5a75"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LlamaTokenizerFast(name_or_path='TinyLlama/TinyLlama-1.1B-Chat-v1.0', vocab_size=32000, model_max_length=2048, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '</s>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
            "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z80MKo9EWiTY",
        "outputId": "22f51b0e-65b1-46d4-f9cc-55453f4015bc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LlamaForCausalLM(\n",
            "  (model): LlamaModel(\n",
            "    (embed_tokens): Embedding(32000, 2048)\n",
            "    (layers): ModuleList(\n",
            "      (0-21): 22 x LlamaDecoderLayer(\n",
            "        (self_attn): LlamaSdpaAttention(\n",
            "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
            "          (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
            "          (v_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
            "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
            "          (rotary_emb): LlamaRotaryEmbedding()\n",
            "        )\n",
            "        (mlp): LlamaMLP(\n",
            "          (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
            "          (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
            "          (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
            "          (act_fn): SiLU()\n",
            "        )\n",
            "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
            "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
            "      )\n",
            "    )\n",
            "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
            "    (rotary_emb): LlamaRotaryEmbedding()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=2048, out_features=32000, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example prompt\n",
        "prompt = \"The cat sat on the\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "print(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQLTDgBzA1nJ",
        "outputId": "9fd8194e-743c-42f2-ef60-a0b7d3652a94"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[   1,  450, 6635, 3290,  373,  278]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward pass through the model (which includes multiple decoder blocks)\n",
        "outputs = model(**inputs)\n",
        "print(len(outputs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3U3Eq2QA5-B",
        "outputId": "463960d6-d4b0-44aa-cc44-2e6528a721e3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Self-Attention in the Llama Decoder Layer\n",
        "\n",
        "Let's create a simplified version of what’s happening in your example, starting with a dummy vocabulary and embedding matrix, and then explore how the self-attention mechanism works, considering the code snippet you provided.\n",
        "\n",
        "### Dummy Vocabulary and Embedding Matrix\n",
        "\n",
        "Let's define a vocabulary of 12 words, where each word is represented by a 5-dimensional embedding:\n",
        "\n",
        "```plaintext\n",
        "[\"the\", \"cat\", \"sat\", \"on\", \"mat\", \"dog\", \"ran\", \"away\", \"bird\", \"flew\", \"tree\", \"house\"]\n",
        "```\n",
        "\n",
        "The embeddings (randomly initialized for simplicity) might look like this:\n",
        "\n",
        "| Token  | Embedding Vector (5-dimensional)       |\n",
        "|--------|----------------------------------------|\n",
        "| the    | [0.1, 0.2, -0.1, 0.4, -0.5]            |\n",
        "| cat    | [-0.2, 0.3, 0.5, -0.1, 0.6]            |\n",
        "| sat    | [0.3, -0.4, 0.2, 0.1, -0.3]            |\n",
        "| on     | [0.1, 0.5, -0.3, 0.2, 0.0]             |\n",
        "| mat    | [-0.5, 0.1, 0.3, -0.2, 0.4]            |\n",
        "| dog    | [0.6, -0.1, 0.2, -0.4, 0.3]            |\n",
        "| ran    | [0.2, -0.3, 0.5, 0.0, -0.1]            |\n",
        "| away   | [-0.1, 0.4, -0.2, 0.3, 0.5]            |\n",
        "| bird   | [0.4, -0.2, 0.1, 0.5, -0.4]            |\n",
        "| flew   | [-0.3, 0.2, 0.0, -0.5, 0.3]            |\n",
        "| tree   | [0.5, -0.4, 0.3, 0.2, -0.1]            |\n",
        "| house  | [0.0, 0.1, -0.5, 0.4, 0.6]             |\n",
        "\n",
        "Each word in this vocabulary is associated with a unique embedding vector of 5 dimensions, which the model uses to capture word meanings in a continuous space.\n",
        "\n",
        "---\n",
        "\n",
        "### Example Code Breakdown\n",
        "\n",
        "Here's a breakdown of the code and how it would operate on this input.\n",
        "\n",
        "#### Loading the Model and Tokenizer\n",
        "```python\n",
        "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "```\n",
        "\n",
        "This code loads a pre-trained TinyLlama model and its tokenizer. The tokenizer converts input text into token IDs, and the model provides functionality to generate text using those token embeddings.\n",
        "\n",
        "#### Encoding the Prompt\n",
        "```python\n",
        "prompt = \"The cat sat on the\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "print(inputs)\n",
        "```\n",
        "\n",
        "The tokenizer converts `\"The cat sat on the\"` into a sequence of token IDs that match the vocabulary. For our dummy vocabulary, assuming `AutoTokenizer` assigns IDs starting from `0`, this might look like:\n",
        "```plaintext\n",
        "{\"the\": 0, \"cat\": 1, \"sat\": 2, \"on\": 3}\n",
        "```\n",
        "\n",
        "This sequence of IDs is transformed into input embeddings, which the model uses to generate the next token.\n",
        "\n",
        "#### Predicting the Next Token\n",
        "```python\n",
        "# Forward pass through the model\n",
        "outputs = model(**inputs)\n",
        "```\n",
        "\n",
        "After processing the input prompt, the model generates a probability distribution over the vocabulary for the next token. The token with the highest probability is selected, decoded back into a word, and printed as the predicted next word.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "In each `LlamaDecoderLayer`, self-attention allows the model to focus on relevant parts of the input when generating the next token. Let's walk through how self-attention is computed with this example.\n",
        "\n",
        "#### Self-Attention Components in `LlamaDecoderLayer`\n",
        "The self-attention layer uses **query (Q)**, **key (K)**, and **value (V)** projections, as well as **output projection (o_proj)** and **rotary embeddings (rotary_emb)**. Here's how each part contributes:\n",
        "\n",
        "1. **Query, Key, and Value Projections**:\n",
        "   - Each input embedding is projected to three vectors: query (Q), key (K), and value (V).\n",
        "   - Let’s say the embedding for \"the\" is `[0.1, 0.2, -0.1, 0.4, -0.5]`. Through linear transformations, we obtain its Q, K, and V vectors:\n",
        "     ```plaintext\n",
        "     Q: [0.3, -0.2, 0.1, 0.4, 0.2]\n",
        "     K: [0.5, -0.1, 0.3, -0.4, 0.0]\n",
        "     V: [0.2, 0.1, -0.3, 0.5, -0.2]\n",
        "     ```\n",
        "   \n",
        "2. **Calculating Attention Scores**:\n",
        "   - The attention score for two tokens is calculated by taking the dot product of their queries and keys. For example, if we compare \"the\" and \"cat\":\n",
        "\n",
        "    $\n",
        "    \\text{Attention Score} = \\text{softmax}\\left( \\frac{Q_{\\text{the}} \\cdot K_{\\text{cat}}}{\\sqrt{d_k}} \\right)\n",
        "    $\n",
        "\n",
        "   - This score determines how much \"the\" attends to \"cat\".\n",
        "\n",
        "3. **Weighted Sum of Values**:\n",
        "   - After computing attention scores for all tokens in the sequence, each token’s final representation in the attention layer is a weighted sum of all other tokens' values, weighted by the attention scores.\n",
        "\n",
        "4. **Output Projection (o_proj)**:\n",
        "   - The weighted sums are then passed through an output projection to return to the embedding dimension.\n",
        "\n",
        "5. **Rotary Embedding (rotary_emb)**:\n",
        "   - Before entering the attention layer, rotary embeddings add position information to each token embedding. This helps the model understand token order in the sequence.\n",
        "\n",
        "---\n",
        "\n",
        "### Example: Self-Attention Calculation with Simple Numbers\n",
        "\n",
        "Imagine we’re calculating the self-attention scores for `\"the cat sat\"`:\n",
        "\n",
        "1. **Generate Q, K, V for Each Token**:\n",
        "   Suppose we have simplified Q, K, and V vectors for each token:\n",
        "   \n",
        "   - \"the\": $ Q = [0.3, -0.2], K = [0.5, -0.1], V = [0.2, 0.1] $\n",
        "   - \"cat\": $ Q = [-0.1, 0.4], K = [0.1, 0.3], V = [-0.2, 0.4] $\n",
        "   - \"sat\": $ Q = [0.4, 0.2], K = [-0.3, 0.2], V = [0.1, -0.3] $\n",
        "\n",
        "2. **Calculate Attention Scores**:\n",
        "   Using \"the\" as the current token, we calculate attention scores with other tokens:\n",
        "   \n",
        "   - Score(\"the\", \"the\") = softmax$( \\frac{[0.3, -0.2] \\cdot [0.5, -0.1]}{\\sqrt{2}} $) = 0.9\n",
        "   - Score(\"the\", \"cat\") = softmax$( \\frac{[0.3, -0.2] \\cdot [0.1, 0.3]}{\\sqrt{2}} $) = 0.1\n",
        "   - Score(\"the\", \"sat\") = softmax$( \\frac{[0.3, -0.2] \\cdot [-0.3, 0.2]}{\\sqrt{2}} $) = 0.2\n",
        "\n",
        "3. **Weighted Sum of Values**:\n",
        "   - The final representation for \"the\" in the attention layer is a weighted sum:\n",
        "   \\[\n",
        "   \\text{Output}_{\\text{the}} = 0.9 \\times [0.2, 0.1] + 0.1 \\times [-0.2, 0.4] + 0.2 \\times [0.1, -0.3]\n",
        "   $\n",
        "\n",
        "This output vector is then passed through `o_proj` and contributes to the model’s next prediction.\n",
        "\n",
        "### Connecting This to Code\n",
        "\n",
        "In your code, when you run `model(**inputs)`, each layer processes the input embeddings through the above self-attention steps. The model’s final logits reflect the self-attention output, with rotary embeddings and fine-tuning adapting the attention to learn new token relationships based on the fine-tuned data.\n",
        "\n",
        "This flow shows how each token considers the rest of the sequence when generating the next word prediction."
      ],
      "metadata": {
        "id": "OqnXuiOdR33o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LlamaMLP\n",
        "The `mlp` (Multi-Layer Perceptron) layer in the `LlamaMLP` block plays a crucial role in further processing the tokens after the self-attention mechanism in each `LlamaDecoderLayer`. Let’s go through each part of this MLP layer and explain what’s happening with respect to your example.\n",
        "\n",
        "In your provided code snippet, the MLP consists of several components:\n",
        "\n",
        "1. **gate_proj**: A linear layer that maps from a 2048-dimensional input to a 5632-dimensional output.\n",
        "2. **up_proj**: Another linear layer that also maps from 2048 dimensions to 5632 dimensions.\n",
        "3. **down_proj**: A linear layer that reduces the 5632-dimensional output back to 2048 dimensions.\n",
        "4. **act_fn (SiLU)**: An activation function applied element-wise to introduce non-linearity.\n",
        "\n",
        "Here’s how this MLP operates on token embeddings produced by the self-attention layer, including a mathematical breakdown of each step.\n",
        "\n",
        "---\n",
        "\n",
        "### Step-by-Step Walkthrough with Your Example Vocabulary\n",
        "\n",
        "The model’s embedding size is **2048** (which is standard in LLaMA models), meaning that each token embedding output from the self-attention layer is a vector of size 2048.\n",
        "\n",
        "After the self-attention layer processes the tokens, each token embedding will go through the MLP to refine the representation further.\n",
        "\n",
        "#### 1. **Input to `gate_proj` and `up_proj` Layers (2048 → 5632)**\n",
        "\n",
        "- The `gate_proj` and `up_proj` layers are both **linear transformations** that map the 2048-dimensional input vector to a 5632-dimensional space.\n",
        "- These two layers are applied in parallel to the input token embedding (let’s call it `x`), resulting in two new 5632-dimensional vectors.\n",
        "\n",
        "For a given token embedding vector $ x $ of shape (2048,), we can think of `gate_proj(x)` and `up_proj(x)` as follows:\n",
        "\n",
        "$\n",
        "\\text{gate_proj}(x) = W_{\\text{gate}} \\cdot x\n",
        "$\n",
        "\n",
        "$\n",
        "\\text{up_proj}(x) = W_{\\text{up}} \\cdot x\n",
        "$\n",
        "where $ W_{\\text{gate}}$ and $ W_{\\text{up}}$ are the weight matrices of shape (5632, 2048) for the `gate_proj` and `up_proj` layers, respectively.\n",
        "\n",
        "These transformations help the model to learn more complex relationships between tokens by increasing the embedding dimensionality.\n",
        "\n",
        "#### 2. **Applying the Activation Function (SiLU)**\n",
        "\n",
        "- The output of `gate_proj(x)` is passed through the **SiLU (Sigmoid Linear Unit)** activation function.\n",
        "- SiLU is defined as:\n",
        "  $\n",
        "  \\text{SiLU}(z) = z \\cdot \\sigma(z)\n",
        "  $\n",
        "  where $ \\sigma(z) $ is the sigmoid function:\n",
        "  $\n",
        "  \\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "  $\n",
        "\n",
        "  This activation function is applied element-wise to the output of `gate_proj(x)`, introducing non-linearity, which allows the network to capture more complex patterns.\n",
        "\n",
        "#### 3. **Element-Wise Multiplication**\n",
        "\n",
        "- The activated output of `gate_proj(x)` is then **element-wise multiplied** with the output of `up_proj(x)`.\n",
        "- This multiplication is sometimes called a **gating mechanism** because it modulates or \"gates\" the information from `up_proj(x)` based on the values from `gate_proj(x)` after applying SiLU.\n",
        "\n",
        "Let:\n",
        "$\n",
        "\\text{gated_output} = \\text{SiLU}\\left(\\text{gate_proj}(x)\\right) \\odot \\text{up_proj}(x)\n",
        "$\n",
        "\n",
        "where $\\odot$ denotes element-wise multiplication.\n",
        "\n",
        "#### 4. **Down Projection (5632 → 2048)**\n",
        "\n",
        "- After the element-wise multiplication, we have a 5632-dimensional vector.\n",
        "- This vector is passed through the `down_proj` layer, which **linearly maps the 5632 dimensions back to 2048 dimensions**:\n",
        "  $\n",
        "  \\text{down_proj}(\\text{gated_output}) = W_{\\text{down}} \\cdot \\text{gated_output}\n",
        "  $\n",
        "\n",
        "  where $ W_{\\text{down}}$ is a weight matrix of shape (2048, 5632).\n",
        "\n",
        "The purpose of this step is to return the vector back to the model’s original embedding size (2048), so it can be combined with other embeddings and layers.\n",
        "\n",
        "---\n",
        "\n",
        "### Summary of the Flow\n",
        "\n",
        "1. **Input**: A 2048-dimensional token embedding from the self-attention layer.\n",
        "2. **`gate_proj` and `up_proj`**: These layers each map the 2048-dimensional input to a 5632-dimensional space.\n",
        "3. **Non-Linearity with SiLU**: The output of `gate_proj` is passed through SiLU activation.\n",
        "4. **Gating Mechanism**: The SiLU-activated `gate_proj` output is multiplied element-wise with the `up_proj` output.\n",
        "5. **`down_proj` Layer**: The gated 5632-dimensional vector is then linearly transformed back to a 2048-dimensional vector.\n",
        "\n",
        "---\n",
        "\n",
        "### Intuition\n",
        "\n",
        "The `LlamaMLP` layer provides a powerful mechanism for the model to transform and refine token embeddings beyond what’s possible with self-attention alone:\n",
        "\n",
        "- **Gating Mechanism**: The SiLU activation in `gate_proj` allows the model to \"turn on or off\" certain parts of the `up_proj` output, effectively gating or controlling the flow of information.\n",
        "- **Dimensionality Expansion and Reduction**: The MLP temporarily increases the dimensionality (2048 to 5632) before bringing it back to 2048. This allows the model to capture complex, high-dimensional relationships and patterns before compressing them back down.\n",
        "\n",
        "In summary, the MLP enhances the model’s ability to learn nuanced patterns in the data by using a combination of linear transformations, non-linear activation, and gating, making it a crucial part of the LLaMA architecture's expressive power.\n",
        "\n",
        "### Example: LlamaMLP Calculation with Simple Numbers\n",
        "To explain the `LlamaMLP` layer using a simplified example, we will use the dummy vocabulary with some simple words and apply a low-dimensional version of the MLP layer, following the same steps from the actual model but with smaller numbers.\n",
        "\n",
        "---\n",
        "\n",
        "### Dummy Vocabulary and Prompt\n",
        "\n",
        "Let’s start with the vocabulary and prompt as you specified:\n",
        "- **Vocabulary**: 12 tokens including `\"the\"`, `\"cat\"`, `\"sat\"`, `\"on\"`, `\"mat\"`, and other filler words.\n",
        "- **Embedding Dimension**: We’ll set it to a lower dimension for simplicity. Instead of 2048 dimensions, let’s use a 5-dimensional embedding.\n",
        "- **Prompt**: `\"The cat sat on the\"`\n",
        "\n",
        "Each token embedding will therefore be represented as a 5-dimensional vector (instead of 2048).\n",
        "\n",
        "---\n",
        "\n",
        "### Step-by-Step Walkthrough Using the Dummy Example\n",
        "\n",
        "Let’s say the MLP in our simplified example has:\n",
        "- `gate_proj` and `up_proj` layers that expand from 5 to 7 dimensions.\n",
        "- `down_proj` layer that reduces from 7 back down to 5 dimensions.\n",
        "\n",
        "So here’s our plan:\n",
        "1. The input embedding vector has 5 dimensions.\n",
        "2. `gate_proj` and `up_proj` expand this vector to 7 dimensions.\n",
        "3. SiLU is applied to the `gate_proj` output.\n",
        "4. Element-wise multiplication is done between the `gate_proj` and `up_proj` outputs.\n",
        "5. `down_proj` reduces the vector back to 5 dimensions.\n",
        "\n",
        "---\n",
        "\n",
        "#### Step 1: Embedding Vector\n",
        "\n",
        "Suppose the token `\"cat\"` has an embedding vector:\n",
        "\n",
        "$\n",
        "x_{\\text{cat}} = \\begin{bmatrix} 1.2 \\\\ -0.5 \\\\ 0.8 \\\\ -1.0 \\\\ 0.3 \\end{bmatrix}\n",
        "$\n",
        "\n",
        "#### Step 2: Passing Through `gate_proj` and `up_proj` (5 → 7 dimensions)\n",
        "\n",
        "- **`gate_proj(x)`**: Let's assume we have a matrix $ W_{\\text{gate}}$ of shape (7, 5) to expand our vector. For simplicity, we’ll generate some numbers.\n",
        "  \n",
        "  Resulting vector (7-dimensional output after `gate_proj`):\n",
        "  $\n",
        "  \\text{gate_proj}(x_{\\text{cat}}) = \\begin{bmatrix} 2.5 \\\\ -1.1 \\\\ 1.7 \\\\ 0.9 \\\\ -0.2 \\\\ 1.0 \\\\ 0.5 \\end{bmatrix}\n",
        "  $\n",
        "\n",
        "- **`up_proj(x)`**: Similarly, using another matrix $ W_{\\text{up}}$ of shape (7, 5).\n",
        "  \n",
        "  Resulting vector (7-dimensional output after `up_proj`):\n",
        "  $\n",
        "  \\text{up_proj}(x_{\\text{cat}}) = \\begin{bmatrix} -0.9 \\\\ 0.5 \\\\ 1.3 \\\\ -0.4 \\\\ 0.8 \\\\ -1.2 \\\\ 1.1 \\end{bmatrix}\n",
        "  $\n",
        "\n",
        "#### Step 3: Applying the SiLU Activation on `gate_proj`\n",
        "\n",
        "The **SiLU activation** function $ \\text{SiLU}(z) = z \\cdot \\sigma(z)$ applies element-wise non-linearity, where $ \\sigma(z) = \\frac{1}{1 + e^{-z}} $.\n",
        "\n",
        "Applying SiLU to `gate_proj(x)`:\n",
        "$\n",
        "\\text{SiLU}(\\text{gate_proj}(x_{\\text{cat}})) = \\begin{bmatrix} 2.12 \\\\ -0.39 \\\\ 1.35 \\\\ 0.62 \\\\ -0.10 \\\\ 0.64 \\\\ 0.31 \\end{bmatrix}\n",
        "$\n",
        "\n",
        "#### Step 4: Element-Wise Multiplication\n",
        "\n",
        "We perform element-wise multiplication between the SiLU-activated `gate_proj` and `up_proj` outputs:\n",
        "$\n",
        "\\text{gated_output} = \\text{SiLU}(\\text{gate_proj}(x_{\\text{cat}})) \\odot \\text{up_proj}(x_{\\text{cat}})\n",
        "$\n",
        "Calculating each element:\n",
        "$\n",
        "\\begin{bmatrix} 2.12 \\times -0.9 \\\\ -0.39 \\times 0.5 \\\\ 1.35 \\times 1.3 \\\\ 0.62 \\times -0.4 \\\\ -0.10 \\times 0.8 \\\\ 0.64 \\times -1.2 \\\\ 0.31 \\times 1.1 \\end{bmatrix} = \\begin{bmatrix} -1.908 \\\\ -0.195 \\\\ 1.755 \\\\ -0.248 \\\\ -0.08 \\\\ -0.768 \\\\ 0.341 \\end{bmatrix}\n",
        "$\n",
        "\n",
        "#### Step 5: Down Projection (7 → 5 dimensions)\n",
        "\n",
        "Finally, we pass the resulting vector through `down_proj`, reducing it from 7 dimensions back to 5.\n",
        "\n",
        "Using a `down_proj` weight matrix $ W_{\\text{down}} $ of shape (5, 7), we can assume the result of this linear transformation is:\n",
        "$\n",
        "\\text{down_proj}(\\text{gated_output}) = \\begin{bmatrix} 0.7 \\\\ -1.1 \\\\ 0.6 \\\\ -0.4 \\\\ 1.2 \\end{bmatrix}\n",
        "$\n",
        "\n",
        "---\n",
        "\n",
        "### Summary of the Process for the Token \"Cat\"\n",
        "\n",
        "For our dummy vocabulary, after passing the embedding vector for `\"cat\"` through the MLP:\n",
        "1. The `gate_proj` and `up_proj` layers expanded the embedding to a higher dimension (5 to 7).\n",
        "2. The SiLU activation applied to the `gate_proj` output added non-linearity.\n",
        "3. Element-wise multiplication with the `up_proj` output introduced gating behavior.\n",
        "4. The `down_proj` layer compressed the representation back to the original embedding size (7 to 5), resulting in a refined vector:\n",
        "   $\n",
        "   \\begin{bmatrix} 0.7 \\\\ -1.1 \\\\ 0.6 \\\\ -0.4 \\\\ 1.2 \\end{bmatrix}\n",
        "   $\n",
        "\n",
        "This new vector can now interact with other embeddings in the model, containing more complex, refined information than the initial embedding alone. This process essentially enhances the representation of each token by adding layers of learned transformations and non-linearities."
      ],
      "metadata": {
        "id": "hedjCW0kUaAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## input_layernorm and post_attention_layernorm\n",
        "\n",
        "In the TinyLlama architecture, the components `input_layernorm` and `post_attention_layernorm` refer to two normalization layers using a technique called **Root Mean Square Normalization (RMSNorm)**. These layers are responsible for normalizing the input and output values during the forward pass of the model, improving the model's stability and training efficiency.\n",
        "\n",
        "Let’s break down these components:\n",
        "\n",
        "### 1. **Input Layer Normalization (input_layernorm)**\n",
        "This normalization is applied at the very start of the model, before the self-attention mechanism.\n",
        "\n",
        "#### Concept:\n",
        "Layer normalization is a method used to normalize the activations across features, i.e., it normalizes the output within each feature (dimension) over the batch. RMSNorm is a variation that uses the **root mean square (RMS)** instead of the standard mean and variance.\n",
        "\n",
        "For an input vector $x$ with $n$ features, RMSNorm normalizes it as follows:\n",
        "\n",
        "$$\n",
        "\\hat{x} = \\frac{x}{\\text{RMS}(x) + \\epsilon}\n",
        "$$\n",
        "\n",
        "Where:\n",
        "- $\\hat{x}$ is the normalized vector,\n",
        "- $\\text{RMS}(x) = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n x_i^2}$ is the root mean square of the input $x$ (i.e., the square root of the average squared values),\n",
        "- $\\epsilon$ is a small constant added to avoid division by zero (typically $1e-5$),\n",
        "- $n$ is the number of features in the input vector.\n",
        "\n",
        "In this case, the input to the model will have 2048 features (as indicated by the dimension `LlamaRMSNorm((2048,)`) that is normalized per feature.\n",
        "\n",
        "### Example:\n",
        "Consider an input vector with 2048 features:\n",
        "\n",
        "$$ x = [x_1, x_2, x_3, \\dots, x_{2048}] $$\n",
        "\n",
        "First, calculate the RMS:\n",
        "\n",
        "$$ \\text{RMS}(x) = \\sqrt{\\frac{1}{2048} \\sum_{i=1}^{2048} x_i^2} $$\n",
        "\n",
        "Then, normalize the input vector:\n",
        "\n",
        "$$ \\hat{x} = \\frac{x}{\\text{RMS}(x) + 1e-5} $$\n",
        "\n",
        "This helps stabilize training by ensuring that the inputs are not too large or small, preventing exploding or vanishing gradients.\n",
        "\n",
        "### 2. **Post-Attention Layer Normalization (post_attention_layernorm)**\n",
        "After the self-attention mechanism, there is another normalization step applied to the outputs of the attention layers. This is important to ensure that the activations remain stable after multiple transformations.\n",
        "\n",
        "#### Concept:\n",
        "The process is similar to the `input_layernorm`, but now the normalization is applied to the outputs from the self-attention and MLP layers. This ensures that the final output after attention and feed-forward passes is normalized and ready for further processing.\n",
        "\n",
        "The same RMSNorm formula is applied here:\n",
        "\n",
        "$$\n",
        "\\hat{y} = \\frac{y}{\\text{RMS}(y) + \\epsilon}\n",
        "$$\n",
        "\n",
        "Where:\n",
        "- $y$ is the output from the attention or MLP layer (which will have 2048 features),\n",
        "- $\\hat{y}$ is the normalized output,\n",
        "- $\\epsilon$ is a small constant ($1e-5$).\n",
        "\n",
        "### Why Normalization?\n",
        "Layer normalization helps the model learn faster and converge more reliably by:\n",
        "- **Stabilizing training**: Reducing the impact of large gradients that could cause instability.\n",
        "- **Improving generalization**: By normalizing activations, the model learns more effectively and generalizes better.\n",
        "\n",
        "### Flow with Mathematical Example:\n",
        "\n",
        "Given the 2048-dimensional vectors from earlier layers (after self-attention or the MLP block):\n",
        "\n",
        "1. **Input Normalization**:\n",
        "   You take the input $x$ (size 2048), calculate the RMS, and normalize the input:\n",
        "\n",
        "   $$ \\hat{x} = \\frac{x}{\\text{RMS}(x) + 1e-5} $$\n",
        "\n",
        "2. **Post-Attention Normalization**:\n",
        "   After processing through the attention or MLP block, you get an output vector $y$. This output is then normalized using the same RMSNorm formula:\n",
        "\n",
        "   $$ \\hat{y} = \\frac{y}{\\text{RMS}(y) + 1e-5} $$\n",
        "\n",
        "In both cases, the purpose is to normalize the vectors so that the learning process is smoother, preventing any individual token or transformation from disproportionately influencing the rest of the network.\n",
        "\n",
        "---\n",
        "\n",
        "So in TinyLlama, the **input_layernorm** normalizes the input embeddings before the attention mechanism, while **post_attention_layernorm** normalizes the output after attention and MLP transformations, ensuring the model trains more effectively."
      ],
      "metadata": {
        "id": "J9UaBLp_b7oa"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9tLQPr4mUZff"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFOHt4FqQ5jn",
        "outputId": "0f5ffa04-cac5-4053-c481-e55b3d120b49"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 6, 32000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs[0]"
      ],
      "metadata": {
        "id": "fn92FwHHpB9O",
        "outputId": "65269562-8faf-422f-aaee-18f9007dffa9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ -4.6822,   0.9866,   4.5126,  ...,  -5.2010,  -2.1646,  -4.2286],\n",
              "         [-10.8859, -10.9407,   1.5036,  ...,  -6.6481,  -8.2838,  -5.6943],\n",
              "         [-10.4763, -10.2798,   3.4586,  ...,  -6.2050,  -8.9359,  -6.1825],\n",
              "         [ -6.7441,  -6.6976,   6.4644,  ...,  -6.0792,  -7.9179,  -5.4411],\n",
              "         [ -7.8823,  -7.3910,   5.8039,  ...,  -4.2936,  -8.5564,  -3.6327],\n",
              "         [ -8.9325,  -8.6203,   3.3090,  ...,  -7.0650,  -7.2374,  -4.4685]]],\n",
              "       grad_fn=<UnsafeViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.logits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcWjKUsRV__C",
        "outputId": "20cb81e4-93a7-4f76-c7b7-bd7eb8a2e010"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 6, 32000])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The logits represent the final output after all decoder blocks\n",
        "next_token_logits = outputs.logits[:, -1, :]  # Logits for the last token\n",
        "next_token_logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnA0rM4zA6v4",
        "outputId": "df2cff9c-6194-45b0-eeac-2c2c79ec8fc2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-8.9325, -8.6203,  3.3090,  ..., -7.0650, -7.2374, -4.4685]],\n",
              "       grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert logits to probabilities and pick the highest\n",
        "next_token = torch.argmax(next_token_logits, dim=-1)\n",
        "print(next_token)\n",
        "predicted_word = tokenizer.decode(next_token)"
      ],
      "metadata": {
        "id": "4keItkdbA_DK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c28dea7-2167-4fcb-bd90-01f528f43890"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1775])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Predicted next word: {predicted_word}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOqj2V7mBJhx",
        "outputId": "21e5e7ae-4f3b-41ec-b3a7-2a997c22ff28"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted next word: mat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code:\n",
        "- The input passes through the **decoder layers** (hidden in the model's forward pass).\n",
        "- Each layer processes the sequence and refines the token representations.\n",
        "- The output logits are computed after all the decoder blocks have processed the input, and the next token is predicted based on the final output from the model.\n",
        "\n",
        "### Summary:\n",
        "\n",
        "The decoder blocks are stacked in layers, where the output of one block is passed as input to the next. Each block refines the understanding of the sequence, attending to previously seen tokens and applying complex transformations to make context-aware predictions. The process continues across all decoder layers, and the final output is used to predict the next token in the sequence. This stacking and refinement of information help the model generate coherent, contextually appropriate text.\n"
      ],
      "metadata": {
        "id": "NNCeAGpFBfSA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fyzC8aufBiYd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s walk through the extended task of writing an email to HR applying for leave due to fever, using the model for text generation. This will involve providing a prompt to the model, and the model will then generate the continuation of the prompt.\n",
        "\n",
        "### Task: Write a mail to HR applying for leave due to fever\n",
        "\n",
        "We'll prompt the model with a sentence, and it will generate the rest of the email, maintaining context and coherence.\n",
        "\n",
        "Here's the extended code:\n",
        "\n",
        "```python\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# Load model and tokenizer\n",
        "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "# Example prompt for the task\n",
        "prompt = \"Dear HR,\\n\\nI am writing to inform you that I am not feeling well due to fever. I would like to request a leave for today. Please let me know if you need any further information.\\n\\nThanks and regards,\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "# Forward pass through the model (which includes multiple decoder blocks)\n",
        "outputs = model(**inputs)\n",
        "\n",
        "# The logits represent the final output after all decoder blocks\n",
        "next_token_logits = outputs.logits[:, -1, :]  # Logits for the last token\n",
        "\n",
        "# Convert logits to probabilities and pick the highest probability token\n",
        "next_token = torch.argmax(next_token_logits, dim=-1)\n",
        "\n",
        "# Decode the predicted token and append to the prompt\n",
        "predicted_word = tokenizer.decode(next_token)\n",
        "\n",
        "# Print the predicted word (this is just one token, but we can generate more if needed)\n",
        "print(f\"Predicted continuation: {predicted_word}\")\n",
        "\n",
        "# If you'd like to generate more tokens and create a longer email:\n",
        "# Generating multiple tokens to form a longer email\n",
        "for _ in range(50):  # Generate 50 tokens\n",
        "    outputs = model(**inputs)\n",
        "    next_token_logits = outputs.logits[:, -1, :]  # Logits for the last token\n",
        "    next_token = torch.argmax(next_token_logits, dim=-1)\n",
        "    predicted_word = tokenizer.decode(next_token)\n",
        "    print(predicted_word, end=\" \")  # Print the continuation\n",
        "    inputs[\"input_ids\"] = torch.cat([inputs[\"input_ids\"], next_token.unsqueeze(0)], dim=-1)  # Append the predicted token\n",
        "```\n",
        "\n",
        "### Explanation of Code:\n",
        "\n",
        "1. **Model and Tokenizer Loading**:\n",
        "   - We load the **TinyLlama** model and its corresponding tokenizer, which are fine-tuned for generating text in a conversational format.\n",
        "\n",
        "2. **Input Prompt**:\n",
        "   - The prompt is a sample email where the user is applying for a leave due to fever. The model will continue the sentence based on this input.\n",
        "\n",
        "3. **Forward Pass**:\n",
        "   - The input prompt is passed to the model in the form of tokenized data (numerical representation of the text).\n",
        "   - The model processes the input through its **decoder layers**, applying self-attention and feed-forward layers to build contextual representations of the tokens.\n",
        "\n",
        "4. **Logits and Token Prediction**:\n",
        "   - The model produces logits for the last token in the sequence, which are raw values representing the likelihood of each token in the vocabulary.\n",
        "   - **Softmax** (implicitly used in the `torch.argmax` operation) is applied to convert the logits into probabilities, and the token with the highest probability is chosen.\n",
        "\n",
        "5. **Predicted Word**:\n",
        "   - The predicted word is decoded back into human-readable text using the tokenizer.\n",
        "\n",
        "6. **Generating Multiple Tokens**:\n",
        "   - If you want to generate more than one token, you can loop and append the new token to the input, creating a continuation of the text. This is how the model keeps building on the previous tokens.\n",
        "\n",
        "### Mathematical Explanation of the Flow:\n",
        "\n",
        "1. **Tokenization**:\n",
        "   Each word in the prompt is tokenized into tokens that are indexed according to the model's vocabulary.\n",
        "\n",
        "   Example:\n",
        "   $\n",
        "   \\text{Prompt}: \"Dear HR, I am writing to inform you that I am not feeling well due to fever.\"\n",
        "   $\n",
        "   Tokenized as:\n",
        "   $\n",
        "   \\text{Tokens} = [Token1, Token2, Token3, \\ldots]\n",
        "   $\n",
        "\n",
        "2. **Embedding**:\n",
        "   Each token is converted into an embedding, which is a high-dimensional vector representation of that token. The embeddings are combined with **positional encodings** to help the model know the order of tokens.\n",
        "\n",
        "   For each token \\( i \\), its embedding \\( \\mathbf{e}_i \\) is:\n",
        "   $\n",
        "   \\mathbf{e}_i = \\text{Embed}(token_i) + \\text{PositionalEncoding}_i\n",
        "   $\n",
        "\n",
        "3. **Self-Attention**:\n",
        "   In the **masked self-attention** layer, each token is transformed into a **query (Q)**, **key (K)**, and **value (V)** vector. The attention score between tokens is calculated using the dot product of the query and key vectors, scaled by the square root of the dimension \\( d \\) of the vectors.\n",
        "\n",
        "   For token \\( i \\) attending to token \\( j \\), the attention score is:\n",
        "   $\n",
        "   \\text{AttentionScore}_{i,j} = \\frac{Q_i \\cdot K_j^T}{\\sqrt{d}}\n",
        "   $\n",
        "   The attention scores are then passed through a **softmax** function to get the attention weights, and these weights are applied to the value vectors \\( V \\) to produce the output for each token.\n",
        "\n",
        "4. **Feed-Forward Network**:\n",
        "   The output from the self-attention layer is passed through a feed-forward neural network to add non-linearity. For token \\( i \\), the final representation is:\n",
        "   $\n",
        "   \\mathbf{r}_i = \\text{FeedForward}(\\mathbf{e}_i)\n",
        "   $\n",
        "\n",
        "5. **Final Layer (Logits)**:\n",
        "   After passing through all the decoder blocks, the output embeddings are passed through a **linear transformation** (projection layer) to convert them into logits, which represent the unnormalized probabilities for each word in the vocabulary.\n",
        "\n",
        "   The logits $ \\mathbf{l}_i $ for token $\\ i $ are computed as:\n",
        "   $\n",
        "   \\mathbf{l}_i = W \\cdot \\mathbf{r}_i + b\n",
        "   $\n",
        "   where \\( W \\) is the weight matrix and \\( b \\) is the bias term.\n",
        "\n",
        "6. **Prediction**:\n",
        "   The logits are passed through **softmax** to generate the probability distribution over the vocabulary. The model predicts the token with the highest probability:\n",
        "   $\n",
        "   \\hat{y}_i = \\arg\\max(\\text{Softmax}(\\mathbf{l}_i))\n",
        "   $\n",
        "\n",
        "7. **Generation**:\n",
        "   The predicted token is appended to the input, and the process repeats until the model has generated the desired continuation.\n",
        "\n",
        "### Example Output:\n",
        "\n",
        "Let's say the model generates a continuation like this:\n",
        "\n",
        "```\n",
        "Dear HR, I am writing to inform you that I am not feeling well due to fever. I would like to request a leave for today. Please let me know if you need any further information. Thanks and regards, [Your Name]\n",
        "```\n",
        "\n",
        "This generated text is based on the model’s understanding of the input prompt and the relationships it has learned during training. The process of masked self-attention helps the model maintain coherence by only considering tokens before the current one in the sequence.\n",
        "\n",
        "### Summary:\n",
        "In this extended code, we used a transformer decoder model to generate a coherent response for a leave application email. The model generates text one token at a time, using the self-attention mechanism to consider previous tokens in the sequence while predicting the next token, ensuring the continuation aligns with the prompt's context."
      ],
      "metadata": {
        "id": "C7nqg3X8L1VM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KdwARbbjMjNO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4MevooMuMjWJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vgnGoXFOMjT2"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}